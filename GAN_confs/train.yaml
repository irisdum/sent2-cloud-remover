### YAML TO THE TRAIN PARAMETERS

train_directory: "/datastore/dum031/data/dataset2/prepro1/input_dataset/train/" #path to the dataset where the train data are stored
val_directory: "/datastore/dum031/data/dataset2/prepro1/input_dataset/val/"  #path where the validation data are stored
## The rescaling between 0 and 1 procedure : recommended, the default set to null RGBN normalization band by band and VV,VH standardization
normalization: true #id set to true normalization to the data is apllied, the norm implemented is standardization for SAR data and normalization for RGBNIR
dict_band_x: {"RGBN":[4,5,6,7],"VV": [0,2],"VH":[1,3]} #the stats for normalization procedure is going to be compute on each of these group of bands
dict_band_label: {"RGBN":[0,1,2,3]}
dict_rescale_type: {"RGBN": "normalization","VV":"standardization","VH":"standardization"}
path_csv: "/datastore/dum031/data/dataset2/" #Path where the csv of the min max of s2 band on a yearb has been computed otherwise set to null
#if path_csv null -> the min, max used to normalize s2 will be the mean of the min, max of the tile in the dataset

## Parameter for the Adam optimizer
lr: 0.0001 #learning rate
fact_g_lr: 1 #multiply lr in the Generator Adam optimiser
beta1: 0.5
lambda: 0 #100 #lambda is the factor applied to the L1 loss abs(||G(z)-y||)


load_model: null #if not null is the iteration where we load our model, the training will start over at ite+1
epoch: 50 #epoch of train of the generator
k_step: 5 #UNUSED
batch_size: 1
training_number: 1
training_dir: "/srv/osirim/idumeur/trainings/" #the model images and checkpoint will be stored at training_dir/trainining_number
# The model will be saved every saving step epoch

im_saving_step: 30 #every n epochs image from the training set are saved
weights_saving_step: 50 # every n epochs the model is saved
metric_step: 50 #every n iterations when the validation metrics are computed. An iteration is the number of batches that goes into the Network
#TRAIN THE GENERATOR MULTIPLE TIME
train_g_multiple_time: [] #[3,4,5,6,7,20,21,22,23]

## DISCRIMINATOR PREVENT OVERFITTING
real_label_smoothing: [1.0,1.0] #if you do not want to apply label smoothing [1,1]
fake_label_smoothing: [0.0,0.0] #if you do not want to apply label smoothing [0,0]

sigma_init: 0.5 #used only if Gaussian noise used in the model definition
sigma_decay: 0.5 # multiply
sigma_step: 10 #every sigma_step iteration sigma decrease from sigma_decay

